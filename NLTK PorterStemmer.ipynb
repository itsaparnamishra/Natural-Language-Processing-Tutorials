{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba33ba37",
   "metadata": {},
   "source": [
    "# In this notebook we can see how stemming is done and what are its drawbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ae7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e1e64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "eat\n",
      "eat\n",
      "eat\n"
     ]
    }
   ],
   "source": [
    "# Stemming a list of words \n",
    "\n",
    "example_words = [\"eat\",\"eats\",\"eating\",\"eated\"]\n",
    "for i in example_words:\n",
    "    print(ps.stem(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c9cf806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play\n",
      "play\n",
      "play\n",
      "play\n"
     ]
    }
   ],
   "source": [
    "example_words = [\"play\",\"playing\",\"played\",\"plays\"]\n",
    "for i in example_words:\n",
    "    print(ps.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fef806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when\n",
      "i\n",
      "studi\n",
      "the\n",
      "letter\n",
      ",\n",
      "messag\n",
      "and\n",
      "mail\n",
      "that\n",
      "i\n",
      "have\n",
      "receiv\n",
      "and\n",
      "also\n",
      "the\n",
      "person\n",
      "interact\n",
      "with\n",
      "the\n",
      "peopl\n",
      ",\n",
      "i\n",
      "can\n",
      "clearli\n",
      "see\n",
      "abund\n",
      "opportun\n",
      "in\n",
      "which\n",
      "everi\n",
      "citizen\n",
      "can\n",
      "contribut\n",
      ".\n",
      "i\n",
      "thought\n",
      "of\n",
      "share\n",
      "thi\n",
      "with\n",
      "you\n",
      ":\n",
      "my\n",
      "topic\n",
      "of\n",
      "thi\n",
      "address\n",
      "will\n",
      "be\n",
      "—\n",
      "“\n",
      "what\n",
      "can\n",
      "i\n",
      "give\n",
      "to\n",
      "my\n",
      "nation\n",
      "?\n",
      "''\n",
      "in\n",
      "indian\n",
      "histori\n",
      ",\n",
      "our\n",
      "nation\n",
      "ha\n",
      "come\n",
      "across\n",
      "a\n",
      "situat\n",
      ",\n",
      "all\n",
      "at\n",
      "a\n",
      "time\n",
      ",\n",
      "an\n",
      "ascend\n",
      "econom\n",
      "trajectori\n",
      ",\n",
      "continu\n",
      "rise\n",
      "foreign\n",
      "exchang\n",
      "reserv\n",
      ",\n",
      "increas\n",
      "domest\n",
      "invest\n",
      "with\n",
      "investor\n",
      "’\n",
      "confid\n",
      "rise\n",
      "steadili\n",
      ",\n",
      "global\n",
      "success\n",
      "of\n",
      "indian\n",
      "manageri\n",
      "and\n",
      "entrepreneuri\n",
      "talent\n",
      ",\n",
      "global\n",
      "recognit\n",
      "of\n",
      "technolog\n",
      "compet\n",
      ",\n",
      "energi\n",
      "of\n",
      "540\n",
      "million\n",
      "youth\n",
      ",\n",
      "umbil\n",
      "connect\n",
      "of\n",
      "more\n",
      "than\n",
      "25\n",
      "million\n",
      "peopl\n",
      "of\n",
      "indian\n",
      "origin\n",
      "in\n",
      "variou\n",
      "part\n",
      "of\n",
      "the\n",
      "planet\n",
      "and\n",
      "the\n",
      "interest\n",
      "shown\n",
      "by\n",
      "mani\n",
      "develop\n",
      "countri\n",
      "to\n",
      "invest\n",
      "in\n",
      "our\n",
      "engin\n",
      "and\n",
      "scientist\n",
      "through\n",
      "set\n",
      "up\n",
      "of\n",
      "new\n",
      "research\n",
      "and\n",
      "develop\n",
      "centr\n",
      "in\n",
      "india\n",
      ".\n",
      "the\n",
      "distinct\n",
      "between\n",
      "the\n",
      "public\n",
      "and\n",
      "the\n",
      "privat\n",
      "sector\n",
      "and\n",
      "the\n",
      "illusori\n",
      "primaci\n",
      "of\n",
      "one\n",
      "over\n",
      "the\n",
      "other\n",
      "is\n",
      "vanish\n",
      ".\n",
      "also\n",
      ",\n",
      "there\n",
      "is\n",
      "a\n",
      "trend\n",
      "that\n",
      "mani\n",
      "young\n",
      "peopl\n",
      "are\n",
      "opt\n",
      "for\n",
      "creat\n",
      "new\n",
      "enterpris\n",
      "instead\n",
      "of\n",
      "be\n",
      "mere\n",
      "employe\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# stem a sentence after tokenizing it\n",
    "\n",
    "text = \"\"\"When I study the letters, messages and mails that I have received and also the personal interactions with the people,\n",
    "I can clearly see abundant opportunities \n",
    "in which every citizen can contribute. I thought of sharing this with you:\n",
    "My topic of this address will be — “What can I give to my nation?\"\n",
    "\n",
    "In Indian history, our nation has come across a situation, all at a time, \n",
    "an ascending economic trajectory, continuously rising foreign exchange reserves,\n",
    "increasing domestic investment with investors’ confidence rising steadily, global \n",
    "successes of Indian managerial and entrepreneurial talents, global recognition of technological competence,\n",
    "energy of 540 million youth, umbilical connectivities of more than 25 million people of Indian origin in\n",
    "various parts of the planet and the interest shown by many developed countries to invest in our engineers \n",
    "and scientists through setting up of new Research and Development Centres in India.\n",
    "\n",
    "The distinction between the public and the private sectors and the illusory primacy of one over the other\n",
    "is vanishing. Also, there is a trend that many young people are opting for creating new enterprises instead\n",
    "of being mere employees.\"\"\"\n",
    "\n",
    "word_tokens = word_tokenize(text)\n",
    "for i in word_tokens:\n",
    "    print(ps.stem(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367eb249",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aa67293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "para = \"\"\"When I study the letters, messages and mails that I have received and also the personal interactions \n",
    "with the people,I can clearly see abundant opportunities in which every citizen can contribute. \n",
    "I thought of sharing this with you:My topic of this address will be — “What can I give to my nation?\"\n",
    "In Indian history, our nation has come across a situation, all at a time, \n",
    "an ascending economic trajectory, continuously rising foreign exchange reserves,\n",
    "increasing domestic investment with investors’ confidence rising steadily, global \n",
    "successes of Indian managerial and entrepreneurial talents, global recognition of technological competence,\n",
    "energy of 540 million youth, umbilical connectivities of more than 25 million people of Indian origin in\n",
    "various parts of the planet and the interest shown by many developed countries to invest in our engineers \n",
    "and scientists through setting up of new Research and Development Centres in India.\n",
    "\n",
    "The distinction between the public and the private sectors and the illusory primacy of one over the other\n",
    "is vanishing. Also, there is a trend that many young people are opting for creating new enterprises instead\n",
    "of being mere employees.\"\"\"\n",
    "\n",
    "\n",
    "sentences = nltk.sent_tokenize(para)\n",
    "\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9921a0cf",
   "metadata": {},
   "source": [
    "## What are stopwords? : All the repeating words in a corpus, for eg - the,of,them,we etc are called stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "160a62f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking all the stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2e1427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords.words('German')   #checking stopwords in German "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39623f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['also', ',', 'trend', 'mani', 'young', 'peopl', 'opt', 'creat', 'new', 'enterpri', 'instead', 'mere', 'employ', '.']\n",
      "also , trend mani young peopl opt creat new enterpri instead mere employ .\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "ps = PorterStemmer()\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [ps.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words)\n",
    "print(words)\n",
    "print(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa7b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem with stemming is that most of the stemmed words have no meaning for example -\n",
    "# \"people\" becomes \"peopl\",\"create\" becomes \"creat\"\n",
    "# likewise more words are converted into meaningless words so we can solve this by lemmatization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
