{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "305479cd",
   "metadata": {},
   "source": [
    "# TF-IDF - Term Frequency Inverse Document Frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9649debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e42a6f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = '''Internet entrepreneurs aren’t the only people that fall into the trap of paying themselves by the hour.\n",
    "Students often make the same mistake.I’ve frequently heard horror stories from friends who complain about the hours spent studying for a big exam.\n",
    "However, many of these people are studying with the television in the background, friends sitting around them or instant messaging applications running.\n",
    "How can you consider that studying? Even if some people get rid of the distractions, there isn’t a studying plan. \n",
    "They simply read and re-read their textbook and notes. \n",
    "No brainstorming for ways to lock in the information instead of just pounding it into their skull.\n",
    "They are too busy “studying” to stop and ask themselves if there is a better way to remember the information sitting in front of them.\n",
    "Studying is hard to measure. It’s an open loop and it isn’t easy to know when you’re finished.\n",
    "Because of this ambiguity, many students slide into the habit of counting hours.\n",
    "Instead of counting hours, I suggest forming a list of tasks that will help you learn the information.\n",
    "Reward yourself for finishing tasks on that list, not for spending another hour locked in your room.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d02685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['internet entrepreneur people fall trap paying hour', 'student often make mistake frequently heard horror story friend complain hour spent studying big exam', 'however many people studying television background friend sitting around instant messaging application running', 'consider studying', 'even people get rid distraction studying plan', 'simply read read textbook note', 'brainstorming way lock information instead pounding skull', 'busy studying stop ask better way remember information sitting front', 'studying hard measure', 'open loop easy know finished', 'ambiguity many student slide habit counting hour', 'instead counting hour suggest forming list task help learn information', 'reward finishing task list spending another hour locked room']\n"
     ]
    }
   ],
   "source": [
    "#cleaning the corpus/text \n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#tokenization \n",
    "sentences = nltk.sent_tokenize(para)\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(sentences)):\n",
    "    result = re.sub('[^a-zA-Z]',' ',sentences[i])\n",
    "    result = result.lower()\n",
    "    result = result.split()\n",
    "    result = [lemmatizer.lemmatize(word) for word in result if word not in set(stopwords.words('english'))]\n",
    "    result = ' '.join(result)\n",
    "    corpus.append(result)\n",
    "    \n",
    "print(corpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e38cc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.40899886,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.29952845, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.42166584, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.35622258, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating TF-IDF model\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer()\n",
    "X = tf.fit_transform(corpus).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56e2669d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 77)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3b2abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
