# Natural-Language-Processing-Tutorials
Getting started with NLP (Basics)


# What is Tokenization ? 
Tokenization is converting paragraphs into list of words and sentences. In order to get our computer to understand text we use tokenization which is basically the breakdown of texts into words,sentences and subwords. Tokenization plays a significant role in dealing with text data.
	
Tokenization is a way of separating a piece of text into smaller units called tokens. 


# What is Stemming ?
Stemming is a technique which is used in NLP to extract the stem word from a branch of words, for example : pull, pulls, pulling, pulled has a stem word "pull".
Some of the stemming algorithms are PorterStemmer,Lancaster Stemming Algorithm, RegexpStemmer ,Snowball stemming algorithm.


# What is Lammatization ?

